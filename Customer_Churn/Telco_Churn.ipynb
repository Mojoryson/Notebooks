{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telco Customer Churn Analysis and Prediction\n",
    "\n",
    "This Notebook provides analysis and prediction of customer churn for a telecommunications company. The notebook includes data loading, exploration, preprocessing, feature engineering, model training, evaluation, and visualization.\n",
    "\n",
    "#### Sections:\n",
    "\n",
    "1. **Import Libraries**\n",
    "   - Import necessary libraries for data manipulation, visualization, and machine learning.\n",
    "   - Suppress warnings for cleaner output.\n",
    "\n",
    "2. **Load & Explore Data**\n",
    "   - Load the Telco Customer Churn dataset.\n",
    "   - Display the first few rows of the dataset to understand its structure.\n",
    "\n",
    "3. **Profile Data**\n",
    "   - Generate a profiling report using `ydata_profiling` to get an overview of the dataset.\n",
    "   - Identify imbalances in the churn data.\n",
    "\n",
    "4. **Data Cleaning & Preprocessing**\n",
    "   - Display column names.\n",
    "   - Analyze demographic data using count plots.\n",
    "   - Clean the `TotalCharges` column by converting it to numeric and handling missing values.\n",
    "\n",
    "5. **Feature Engineering**\n",
    "   - Separate categorical and numerical features.\n",
    "   - Encode categorical features using `LabelEncoder`.\n",
    "   - Merge numerical and encoded categorical features into a final DataFrame.\n",
    "\n",
    "6. **Split Data**\n",
    "   - Drop missing values and unnecessary columns.\n",
    "   - Split the data into training and testing sets.\n",
    "\n",
    "7. **Handle the Churn Imbalance**\n",
    "   - Use SMOTE (Synthetic Minority Over-sampling Technique) to balance the training dataset.\n",
    "\n",
    "8. **Train the Model**\n",
    "   - Train a RandomForestClassifier on the balanced training data.\n",
    "\n",
    "9. **Make Predictions**\n",
    "   - Make predictions on the test data and calculate accuracy.\n",
    "\n",
    "10. **Example of Binning**\n",
    "    - Demonstrate feature engineering by binning the `tenure` column into predefined categories.\n",
    "\n",
    "11. **Hyperparameter Tuning with GridSearchCV**\n",
    "    - Perform hyperparameter tuning using GridSearchCV to find the best parameters for the RandomForestClassifier.\n",
    "\n",
    "12. **Evaluating the Model on the Test Set**\n",
    "    - Evaluate the model using classification metrics and ROC AUC score.\n",
    "\n",
    "13. **Evaluate the Model**\n",
    "    - Calculate and print evaluation metrics (accuracy, precision, recall, F1-score, ROC AUC).\n",
    "    - Plot confusion matrix, ROC curve, and precision-recall curve for visual evaluation.\n",
    "\n",
    "### Key Steps and Outputs:\n",
    "\n",
    "- **Data Loading and Exploration**: Load the dataset and display the first few rows to understand the data structure.\n",
    "- **Data Profiling**: Generate a profiling report to get an overview of the dataset and identify imbalances.\n",
    "- **Data Cleaning**: Clean the `TotalCharges` column and handle missing values.\n",
    "- **Feature Engineering**: Encode categorical features and bin the `tenure` column.\n",
    "- **Model Training**: Train a RandomForestClassifier and perform hyperparameter tuning.\n",
    "- **Model Evaluation**: Evaluate the model using various metrics and visualize the results.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "This notebook provides a detailed workflow for analyzing and predicting customer churn using machine learning techniques. It includes data preprocessing, feature engineering, model training, hyperparameter tuning, and evaluation, making it a comprehensive guide for similar predictive modeling tasks.\n",
    "\n",
    "- Â© 2025 CodeRod Solutions LLC. All rights reserved.\n",
    "- Author Rod Morrison with inspiration from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Telco_Customer_Churn.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile Data\n",
    "\n",
    "profile = ProfileReport(df, title=\"Telco Customer Churn Profiling Report\")\n",
    "profile.to_file('data/Telco_Customer_Churn.html')\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report shows an imbalance in the churn (only 26.5%) - will need to balance for the training data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Demographic Data\n",
    "\n",
    "\n",
    "cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents']\n",
    "numerical = cols\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "for i, col in enumerate(numerical):\n",
    "    ax = plt.subplot(1, len(numerical), i+1)\n",
    "    sns.countplot(x=str(col), data=df, palette=[\"blue\", \"yellow\"])\n",
    "    ax.set_title(f\"{col}\")\n",
    "    \n",
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=df, palette=[\"blue\", \"yellow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['InternetService',\"TechSupport\",\"OnlineBackup\",\"Contract\"]\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    ax = plt.subplot(1, len(cols), i+1)\n",
    "    sns.countplot(x =\"Churn\", hue = str(col), data = df)\n",
    "    ax.set_title(f\"{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "df['TotalCharges'] = df['TotalCharges'].apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df.drop(['customerID','TotalCharges','MonthlyCharges','SeniorCitizen','tenure'],axis=1)\n",
    "\n",
    "cat_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_cat = cat_features.apply(le.fit_transform)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df[['customerID','TotalCharges','MonthlyCharges','SeniorCitizen','tenure']]\n",
    "finaldf = pd.merge(num_features, df_cat, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = finaldf.dropna()\n",
    "finaldf = finaldf.drop(['customerID'],axis=1)\n",
    "\n",
    "X = finaldf.drop(['Churn'],axis=1)\n",
    "y = finaldf['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle the Churn Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(k_neighbors=5)\n",
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)\n",
    "X_train, y_train = X_smote, y_smote\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=46)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(X_test)\n",
    "pred_prob = rf.predict_proba(X_test)[:, 1]  # Get predicted probabilities for ROC and PR curves\n",
    "\n",
    "print(accuracy_score(preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Feature Engineering - Binning Tenure\n",
    "\n",
    "def bin_tenure(tenure):\n",
    "    \"\"\"\n",
    "    Bins the tenure of a customer into predefined categories.\n",
    "\n",
    "    Args:\n",
    "        tenure (int): The tenure of the customer in months.\n",
    "\n",
    "    Returns:\n",
    "        str: The tenure category (e.g., \"0-6 Months\", \"6-12 Months\", etc.).\n",
    "    \"\"\"\n",
    "    if tenure <= 6:\n",
    "        return \"0-6 Months\"\n",
    "    elif tenure <= 12:\n",
    "        return \"6-12 Months\"\n",
    "    elif tenure <= 24:\n",
    "        return \"12-24 Months\"\n",
    "    elif tenure <= 36:\n",
    "        return \"24-36 Months\"\n",
    "    else:\n",
    "        return \"36+ Months\"\n",
    "\n",
    "finaldf['Tenure_Binned'] = finaldf['tenure'].apply(bin_tenure)\n",
    "\n",
    "print(finaldf[['tenure', 'Tenure_Binned']].head())  # Verify the new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries for Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3,  # 3-fold cross-validation\n",
    "                           scoring='roc_auc', # Use ROC AUC for evaluation\n",
    "                           verbose=2) # Show progress\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best ROC AUC Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating the Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Import Libraries for Model Evaluation\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Evaluating the Model on the Test Set\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, best_rf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "roc_auc = roc_auc_score(y_test, pred_prob)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
